本研究的目标是设计一个多模型机器学习推理服务的调度框架，该框架旨在将传入的推理请求分配到最少数量的GPU上，同时最大化它们的利用率。对于具有服务水平目标（SLO）要求的ML推理工作负载调度，必须考虑三个方面：批处理、时间调度和空间调度。与以往只考虑这三个维度中的部分内容的方法不同，本文提出了一种全面探索这三个维度的调度器，以寻找最有效的调度点。

研究中利用GPU的空间共享能力，引入了一种GPU分区的抽象，称为gpulet。多个gpulet可以通过时间和空间共享来使用同一GPU。对于每个训练好的ML模型，离线收集一个最小性能概况。基于这些模型的概况，调度器将任务分配给多个物理GPU上的gpulet。我们的调度框架在满足当前请求速率和SLO要求的情况下，最小化所需的物理GPU数量。此外，框架还通过适应请求速率的变化自动扩展GPU服务器的数量。

调度器的总体架构由前端服务器和多个后端服务器组成。前端服务器负责做出调度决策，而后端服务器执行这些决策。前端的调度器决定并将批量请求发送给后端服务器，每个后端服务器的执行器将请求分派到GPU。调度决策利用每个模型的性能档案（例如，SLO和一对批处理大小及分区大小的推理延迟）和传入请求速率来制定。

请求监控器跟踪每个模型每秒的新到达请求数量。基于跟踪的请求速率，如果请求速率的变化足够显著，gpulet调度器将决定是否需要重新组织分区。如果需要重新组织，将新的分区比率发送给负责需要重新组织的GPU的后端服务器。后端服务器中的分区管理器为GPU准备分区，以便它们能够根据新的分区比率处理请求。调度周期根据GPU分区延迟经验性地确定，以便通过调度窗口隐藏分区的开销。

本研究旨在设计一个多模型机器学习推理服务的调度框架，主要贡献和关键点如下：

1. **调度框架目标**：将传入推理请求分配到最少数量的GPU，最大化其利用率，满足SLO要求。

2. **考虑三个方面**：
   - **批处理**：对请求进行有效的批量处理。
   - **时间调度**：动态管理任务的执行时间。
   - **空间调度**：利用GPU的空间共享能力。

3. **引入gpulet概念**：gpulet是GPU分区的抽象，允许多个gpulet通过时间和空间共享来使用同一物理GPU。

4. **性能档案**：每个模型的性能档案在离线状态下收集，以指导调度决策。

5. **自动扩展**：框架根据请求速率变化自动调整所需的GPU服务器数量。

6. **调度器架构**：
   - **前端服务器**：负责调度决策。
   - **后端服务器**：执行调度决策，处理请求。

7. **请求监控**：实时跟踪每个模型的请求到达率，决定是否需要重新组织GPU分区。

8. **调度周期**：经验性确定，以隐藏分区调整的开销。

通过这些措施，研究实现了在满足性能要求的同时，优化了GPU资源的利用效率。