本研究旨在设计一个多模型机器学习推理服务的调度框架，主要贡献和关键点如下：

1. **调度框架目标**：将传入推理请求分配到最少数量的GPU，最大化其利用率，满足SLO要求。

2. **考虑三个方面**：
   - **批处理**：对请求进行有效的批量处理。
   - **时间调度**：动态管理任务的执行时间。
   - **空间调度**：利用GPU的空间共享能力。

3. **引入gpulet概念**：gpulet是GPU分区的抽象，允许多个gpulet通过时间和空间共享来使用同一物理GPU。

4. **性能档案**：每个模型的性能档案在离线状态下收集，以指导调度决策。

5. **自动扩展**：框架根据请求速率变化自动调整所需的GPU服务器数量。

6. **调度器架构**：
   - **前端服务器**：负责调度决策。
   - **后端服务器**：执行调度决策，处理请求。

7. **请求监控**：实时跟踪每个模型的请求到达率，决定是否需要重新组织GPU分区。

8. **调度周期**：经验性确定，以隐藏分区调整的开销。

通过这些措施，研究实现了在满足性能要求的同时，优化了GPU资源的利用效率。





本研究调查了 SLO 感知的 ML 推理服务器设计。研究发现，当批量大小受到限制以满足 SLO 设置的响应时间限制时，常见的 ML 模型执行无法充分利用 GPU 计算资源。通过**利用空间分区功能**，我们的框架显着**提高了多 GPU 配置的吞吐量**，同时支持 SLO。基于新的时空调度技术，本研究表明 GPU 资源的新抽象 (gpulet) 可以改善 SLO 下的 ML 推理服务。源代码可在 https://github.com/casys-kaist/glet 获取。